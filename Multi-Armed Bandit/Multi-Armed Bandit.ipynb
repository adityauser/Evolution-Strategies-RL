{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'arms': '10', #numbers of arms in MAB problems\n",
    "    'non_stationary' False #flag for non-stationary environment\n",
    "    'mutation_mag': '0.01', #mutation magnitude\n",
    "    'pop_size': '50', #population size\n",
    "    'max_gen': '200',#number of generations\n",
    "    'hidden': '32', #number of nodes in each layer\n",
    "    'layers': '1', #number of layers\n",
    "    'name': 'UCBvsES', #name of the experiment\n",
    "    'save_result': True, #flag for saving the result\n",
    "    'noise': False, #add noise in the output layer of ANN\n",
    "    'trials': '100', #number arms selected by each agent\n",
    "    'message': '' #note for the experiment    \n",
    "}\n",
    "\n",
    "#Saving and logging\n",
    "import logging\n",
    "import os\n",
    "\n",
    "if args['save_result']:\n",
    "    try:\n",
    "        os.makedirs('results/'+args['layers'] + 'x' + args['hidden'] + 'mag' + args['mutation_mag'] + 'arms' + args['arms'] + 'psize' + args['pop_size'] + 'trials' + args['trials'] + args['name'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "LOG_FILENAME = 'results/'+args['layers'] + 'x' + args['hidden'] + 'mag' + args['mutation_mag'] + 'arms' + args['arms'] + 'psize' + args['pop_size'] + 'trials' + args['trials'] + args['name'] + '/UCBvsES.log'\n",
    "logging.basicConfig(filename=LOG_FILENAME,level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Enviroment:\n",
    "    '''Create and setuo MAB Environment\n",
    "    Public Functions:\n",
    "        reset: reset the MAB environment\n",
    "        pull_arm: pull the given arm and return the corresponding reward\n",
    "    Private Functions:\n",
    "        linear_change: update the mean reward corresponing to each arm in linear fasion\n",
    "        pull_arm_bernaulli: pull given arm and return reward according to bernaulli distribution\n",
    "        pull_arm_gaussion: pull given arm and return reward according to gaussion distribution\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, is_bernoulli, no_arms=10, N=100):\n",
    "        self.no_arms = no_arms       \n",
    "        self.pull_arm = self.pull_arm_bernaulli if is_bernoulli else self.pull_arm_gaussion\n",
    "        \n",
    "        #maximum number arms that can be selected by each agent\n",
    "        self.N = N \n",
    "        #\n",
    "        self.round = 0        \n",
    "        self.theta2 = np.random.rand(no_arms) \n",
    "            \n",
    "        self.arms_prob = {}\n",
    "        for arm in range(self.no_arms):\n",
    "            self.arms_prob[arm] = np.random.rand()\n",
    "            \n",
    "        self.arms_grad = {}\n",
    "        for arm in range(self.no_arms):\n",
    "            self.arms_grad[arm] = (np.random.rand() - self.arms_prob[arm])/self.N\n",
    "        \n",
    "        self.best_arm = np.argmax([[self.arms_prob[arm] for arm in range(self.no_arms)]])\n",
    "        \n",
    "    def reset(self):\n",
    "        self.round = 0\n",
    "        for arm in range(self.no_arms):\n",
    "            self.arms_prob[arm] = np.random.rand()\n",
    "        for arm in range(self.no_arms):\n",
    "            self.arms_grad[arm] = (np.random.rand() - self.arms_prob[arm])/self.N\n",
    "        self.best_arm = np.argmax([[self.arms_prob[arm] for arm in range(self.no_arms)]])\n",
    "     \n",
    "    def linear_change(self):  \n",
    "        if not self.round > self.N:\n",
    "            for arm in range(self.no_arms):\n",
    "                self.arms_prob[arm] += self.arms_grad[arm]\n",
    "        else:\n",
    "            raise TypeError(\"Enviroment has reached to maximum pulls, reset the enviroment.\")\n",
    "        \n",
    "        self.best_arm = np.argmax([[self.arms_prob[arm] for arm in range(self.no_arms)]])\n",
    "    \n",
    "        \n",
    "    def pull_arm_bernaulli(self, arm):\n",
    "        if args['non_stationary']:\n",
    "            self.round += 1\n",
    "            self.linear_change()\n",
    "        \n",
    "        return 1 if self.arms_prob[arm] > np.random.rand() else 0\n",
    "    \n",
    "    def pull_arm_gaussion(self, arm):\n",
    "        return np.random.normal(self.arms_prob[arm], scale=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AgentUCB:\n",
    "    '''Create an UCB agent\n",
    "    Functions:\n",
    "        pull: select the arm according to the UCB algorithm; returns arm\n",
    "        reset: reset the UCB agent i.e. delete the stastical data\n",
    "        update: update the value corresponding to each arm\n",
    "    '''\n",
    "    def __init__(self, no_arms=10):\n",
    "        self.no_arms = no_arms\n",
    "        self.info = {}\n",
    "        for arm in range(self.no_arms):\n",
    "            self.info[arm] = {}\n",
    "            self.info[arm]['likely'] = 0\n",
    "            self.info[arm]['no_visited'] = 0\n",
    "            self.info[arm]['is_visited'] = False\n",
    "            self.info[arm]['value'] = 0\n",
    "        self.round = 0\n",
    "        self.score = 0\n",
    "        \n",
    "    def pull(self):\n",
    "        self.round += 1\n",
    "        \n",
    "        for arm in range(self.no_arms):\n",
    "            if not self.info[arm]['is_visited']:\n",
    "                self.info[arm]['is_visited'] = True\n",
    "                self.info[arm]['no_visited'] += 1\n",
    "                return arm\n",
    "            \n",
    "        arm = np.argmax(np.asarray([self.info[arm]['likely'] for arm in range(self.no_arms)]))\n",
    "        self.info[arm]['no_visited'] += 1\n",
    "        \n",
    "        return arm\n",
    "    \n",
    "    def reset(self):\n",
    "        self.info = {}\n",
    "        for arm in range(self.no_arms):\n",
    "            self.info[arm] = {}\n",
    "            self.info[arm]['likely'] = 0\n",
    "            self.info[arm]['no_visited'] = 0\n",
    "            self.info[arm]['is_visited'] = False\n",
    "            self.info[arm]['value'] = 0\n",
    "        self.round = 0    \n",
    "    \n",
    "    def update(self, action, reward):\n",
    "        \n",
    "        self.info[action]['value'] += (reward-self.info[action]['value'])/self.info[action]['no_visited']\n",
    "        \n",
    "        if all([self.info[arm]['is_visited'] for arm in range(self.no_arms)]):\n",
    "            for arm in range(self.no_arms):\n",
    "                self.info[arm]['likely'] = self.info[arm]['value'] + np.sqrt((2*np.log(self.round))/self.info[arm]['no_visited'])\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.autograd import Variable,grad\n",
    "\n",
    "import copy\n",
    "import operator\n",
    "import collections\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#global archive to keep track of states sampled from environment\n",
    "state_archive = collections.deque([], 100)\n",
    "\n",
    "#default feed-forward net architecture\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, action_space,settings={}):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        _b = True\n",
    "        hid_layers = int(args['layers']) #how many hidden layers\n",
    "        sz = int(args['hidden']) #how many neurons per layer\n",
    "\n",
    "        num_outputs = action_space\n",
    "\n",
    "        #overwritable defaults\n",
    "        af = nn.ReLU \n",
    "        oaf = nn.Sigmoid\n",
    "        \n",
    "\n",
    "        afunc = {'relu':nn.ReLU,'tanh':nn.Tanh,'linear':lambda : linear,'sigmoid':nn.Sigmoid}\n",
    "        \n",
    "        self.stddev = 0.1\n",
    "        self._af = af\n",
    "        self.af = af()\n",
    "        self.sigmoid = oaf()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        #first fully-connected layer changing from input-size representation to hidden-size representation\n",
    "        self.fc1 = nn.Linear(num_inputs, sz, bias=_b) \n",
    "\n",
    "        self.hidden_layers = []\n",
    "\n",
    "        #create all the hidden layers\n",
    "        for x in range(hid_layers):\n",
    "            self.hidden_layers.append(nn.Linear(sz, sz, bias=True))\n",
    "            self.add_module(\"hl%d\"%x,self.hidden_layers[-1])\n",
    "\n",
    "        #create the hidden -> output layer\n",
    "        self.fc_out = nn.Linear(sz, num_outputs, bias=_b)\n",
    "\n",
    "        self.train()\n",
    "\n",
    "    def forward(self, inputs, intermediate=None, debug=False):\n",
    "\n",
    "        x = inputs\n",
    "        x = torch.cat(x, axis=1)\n",
    "        #fully connection input -> hidden\n",
    "        x = self.fc1(x.float())\n",
    "            \n",
    "        x = self._af()(x)\n",
    "        \n",
    "        #propagate signal through hidden layers\n",
    "        for idx,layer in enumerate(self.hidden_layers):\n",
    "\n",
    "            #do fc computation\n",
    "            x = layer(x)\n",
    "\n",
    "            #run it through activation function\n",
    "            x = self._af()(x)\n",
    "\n",
    "            if intermediate == idx:\n",
    "                cached = x\n",
    "        \n",
    "        #output layer\n",
    "        x = self.fc_out(x)\n",
    "        #Add noise\n",
    "        if args['noise']:            \n",
    "            x = x+torch.autograd.Variable(torch.randn(x.size()).cpu() * self.stddev)\n",
    "        #softmax\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        if intermediate!=None:\n",
    "            return x,cached\n",
    "\n",
    "        return x\n",
    "    \n",
    "    #function to grab current flattened neural network weights\n",
    "    def extract_parameters(self):\n",
    "        tot_size = self.count_parameters()\n",
    "        pvec = np.zeros(tot_size, np.float32)\n",
    "        count = 0\n",
    "        for param in self.parameters():\n",
    "            sz = param.data.numpy().flatten().shape[0]\n",
    "            pvec[count:count + sz] = param.data.numpy().flatten()\n",
    "            count += sz\n",
    "        return pvec.copy()\n",
    "    \n",
    "    #function to inject a flat vector of ANN parameters into the model's current neural network weights\n",
    "    def inject_parameters(self, pvec):\n",
    "        tot_size = self.count_parameters()\n",
    "        count = 0\n",
    "\n",
    "        for param in self.parameters():\n",
    "            sz = param.cpu().data.numpy().flatten().shape[0]\n",
    "            raw = pvec[count:count + sz]\n",
    "            reshaped = raw.reshape(param.cpu().data.numpy().shape)\n",
    "            param.data = torch.from_numpy(reshaped).float()\n",
    "            count += sz\n",
    "\n",
    "        return pvec\n",
    "\n",
    "    #count how many parameters are in the model\n",
    "    def count_parameters(self):\n",
    "        count = 0\n",
    "        for param in self.parameters():\n",
    "            #print param.data.numpy().shape\n",
    "            count += param.cpu().data.numpy().flatten().shape[0]\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Individual:\n",
    "    '''Create an individual who is compatible\n",
    "    Public Functions:\n",
    "        pull: select the arm accroding to the NN model\n",
    "        reset: reset the UCB agent i.e. delete the stastical data\n",
    "        mutate: mutate itself according to SM-G-SO algorithm and return the child\n",
    "        run: evaluate in all the given environments\n",
    "    Private Functions:\n",
    "        mutate_sm_g: Add mutation to the genome according to safe mutation technique.\n",
    "        \n",
    "    '''\n",
    "    def __init__(self, no_arms=10, mag=0.1, trials=50):\n",
    "        self.no_arms = no_arms\n",
    "        self.mag = mag\n",
    "        self.trials = trials\n",
    "        self.net_rwd = 0\n",
    "        self.score = 0\n",
    "        self.fitness = 0\n",
    "        self.matches = 0\n",
    "        self.played = False\n",
    "        self.buffer = []\n",
    "        self.model = Model(no_arms*2, no_arms)\n",
    "        self.info = {}\n",
    "        for arm in range(self.no_arms):\n",
    "            self.info[arm] = {}\n",
    "            self.info[arm]['no_visited'] = 0\n",
    "            self.info[arm]['value'] = 0\n",
    "        \n",
    "    def pull(self):\n",
    "        visits = torch.Tensor([normalize([np.array([self.info[arm]['no_visited'] for arm in range(self.no_arms)])]).ravel()])\n",
    "        values = torch.Tensor([np.array([self.info[arm]['value'] for arm in range(self.no_arms)])])\n",
    "        actions = self.model([visits, values])\n",
    "        self.buffer.append([visits[0].numpy(), values[0].numpy()])\n",
    "        try:\n",
    "            arm = np.random.choice(self.no_arms, 1, p=actions[0].detach().numpy())[0]\n",
    "            #arm  = np.argmax(actions[0].detach().numpy())\n",
    "        except:\n",
    "            raise TypeError('actions:', actions)\n",
    "        self.info[arm]['no_visited'] += 1\n",
    "        return arm\n",
    "    \n",
    "    def reset(self):\n",
    "        self.buffer = []\n",
    "        self.info = {}\n",
    "        for arm in range(self.no_arms):\n",
    "            self.info[arm] = {}\n",
    "            self.info[arm]['no_visited'] = 0\n",
    "            self.info[arm]['value'] = 0\n",
    "\n",
    "    \n",
    "    def mutate(self, mag=None, **kwargs):\n",
    "        if mag==None:\n",
    "            mag = self.mag\n",
    "        parameters = self.model.extract_parameters()\n",
    "        child = Individual(self.no_arms, self.mag, self.trials)\n",
    "        genome = self.mutate_sm_g('SM-G-SO', parameters, child.model, states=None, mag=mag, **kwargs)\n",
    "        child.model.inject_parameters(genome.astype(float)) \n",
    "        return child\n",
    "    \n",
    "    def mutate_sm_g(self, mutation, params, model, verbose=False, states=None, mag=0.1, **kwargs):\n",
    "\n",
    "        global state_archive\n",
    "\n",
    "        #inject parameters into current model\n",
    "        model.inject_parameters(params.copy())\n",
    "\n",
    "        #if no states passed in, use global state archive\n",
    "        if states == None:\n",
    "            states = state_archive\n",
    "\n",
    "        #sub-sample experiences from parent\n",
    "        sz = min(100,len(states))\n",
    "\n",
    "\n",
    "        np_obs = random.sample(states, sz)\n",
    "        verification_states = Variable(\n",
    "            torch.from_numpy(np.array([i[0] for i in np_obs])), requires_grad=False)\n",
    "        verification_mask = Variable(\n",
    "            torch.from_numpy(np.array([i[1] for i in np_obs])), requires_grad=False)\n",
    "\n",
    "        #run experiences through model\n",
    "        old_policy = model([verification_states, verification_mask])\n",
    "        num_outputs = old_policy.size()[1]\n",
    "\n",
    "        abs_gradient=False \n",
    "        avg_over_time=False\n",
    "        second_order=False\n",
    "\n",
    "        if mutation.count(\"ABS\")>0:\n",
    "            abs_gradient=True\n",
    "            avg_over_time=True\n",
    "        if mutation.count(\"SO\")>0:\n",
    "            second_order=True\n",
    "\n",
    "        #generate normally-distributed perturbation i.e. gaussion mutation\n",
    "        delta = np.random.randn(*params.shape).astype(np.float32)*mag\n",
    "\n",
    "        if second_order:\n",
    "            if verbose:\n",
    "                print ('SM-G-SO')\n",
    "            np_copy = np.array(old_policy.data.numpy(),dtype=np.float32)\n",
    "            _old_policy_cached = Variable(torch.from_numpy(np_copy), requires_grad=False)\n",
    "            loss =  ((old_policy-_old_policy_cached)**2).sum(1).mean(0)\n",
    "            loss_gradient = grad(loss, model.parameters(), create_graph=True)\n",
    "            flat_gradient = torch.cat([grads.view(-1) for grads in loss_gradient]) #.sum()\n",
    "\n",
    "            direction = (delta/ np.sqrt((delta**2).sum()))\n",
    "            direction_t = Variable(torch.from_numpy(direction),requires_grad=False)\n",
    "            grad_v_prod = (flat_gradient * direction_t).sum()\n",
    "            second_deriv = torch.autograd.grad(grad_v_prod, model.parameters())\n",
    "            sensitivity = torch.cat([g.contiguous().view(-1) for g in second_deriv])\n",
    "            scaling = torch.sqrt(torch.abs(sensitivity).data)\n",
    "\n",
    "        elif not abs_gradient:\n",
    "            print (\"SM-G-SUM\")\n",
    "            tot_size = model.count_parameters()\n",
    "            jacobian = torch.zeros(num_outputs, tot_size)\n",
    "            grad_output = torch.zeros(*old_policy.size())\n",
    "\n",
    "            for i in range(num_outputs):\n",
    "                model.zero_grad()   \n",
    "                grad_output.zero_()\n",
    "                grad_output[:, i] = 1.0\n",
    "                old_policy.backward(grad_output, retain_graph=True)\n",
    "                jacobian[i] = torch.from_numpy(model.extract_grad())\n",
    "\n",
    "            scaling = torch.sqrt(  (jacobian**2).sum(0) )\n",
    "\n",
    "        else:\n",
    "            print (\"SM-G-ABS\")\n",
    "            tot_size = model.count_parameters()\n",
    "            jacobian = torch.zeros(num_outputs, tot_size, sz)\n",
    "            grad_output = torch.zeros([1,num_outputs]) #*old_policy.size())\n",
    "\n",
    "            for i in range(num_outputs):\n",
    "                for j in range(sz):\n",
    "                    old_policy_j = model([verification_states[j:j+1], verification_mask.squeeze(1)[j:j+1]])\n",
    "                    model.zero_grad()   \n",
    "                    grad_output.zero_()\n",
    "\n",
    "                    grad_output[0, i] = 1.0\n",
    "\n",
    "                    old_policy_j.backward(grad_output, retain_graph=True)\n",
    "                    jacobian[i,:,j] = torch.from_numpy(model.extract_grad())\n",
    "\n",
    "            mean_abs_jacobian = torch.abs(jacobian).mean(2)\n",
    "            scaling = torch.sqrt( (mean_abs_jacobian**2).sum(0))\n",
    "\n",
    "        scaling = scaling.numpy()\n",
    "\n",
    "        #Avoid divide by zero error \n",
    "        #(intuition: don't change parameter if it doesn't matter)\n",
    "        scaling[scaling==0]=1.0\n",
    "\n",
    "        #Avoid straying too far from first-order approx \n",
    "        #(intuition: don't let scaling factor become too enormous)\n",
    "        scaling[scaling<0.01]=0.01\n",
    "\n",
    "        #rescale perturbation on a per-weight basis\n",
    "        delta /= scaling\n",
    "\n",
    "        #delta should be less if fitness is high\n",
    "        #delta *= -np.log((fitness+1)/2)\n",
    "        #print(\"Sum of delta changed from {} to {}\".format(sum(delta/np.log((fitness+1)/2)), sum(delta)))\n",
    "\n",
    "        #generate new perturbation\n",
    "        new_params = params+delta\n",
    "\n",
    "        model.inject_parameters(new_params)\n",
    "        old_policy = old_policy.data.numpy()\n",
    "\n",
    "        #restrict how far any dimension can vary in one mutational step\n",
    "        weight_clip = 0.2\n",
    "\n",
    "        #currently unused: SM-G-*+R (using linesearch to fine-tune)\n",
    "        mult = 0.05\n",
    "\n",
    "        if mutation.count(\"R\")>0:\n",
    "            linesearch=True\n",
    "            threshold = mag\n",
    "        else:\n",
    "            linesearch=False\n",
    "\n",
    "        if linesearch == False:\n",
    "            search_rounds = 0\n",
    "        else:\n",
    "            search_rounds = 15\n",
    "\n",
    "        def search_error(x,raw=False):\n",
    "            '''Calculate divergance between policies/models\n",
    "            Args:\n",
    "                x: Inputs\n",
    "                raw: flag for returning relative to mutation magnitude\n",
    "            Returns:\n",
    "                change: term similar to divergance\n",
    "            '''\n",
    "            final_delta = delta*x\n",
    "            final_delta = np.clip(final_delta,-weight_clip,weight_clip)\n",
    "            new_params = params + final_delta\n",
    "            model.inject_parameters(new_params)\n",
    "\n",
    "            output = model([verification_states, verification_mask.squeeze(1)]).data.numpy()\n",
    "            change = np.sqrt(((output - old_policy)**2).sum(1)).mean()\n",
    "\n",
    "            if raw:\n",
    "                return change\n",
    "\n",
    "            return (change-threshold)**2\n",
    "\n",
    "        if linesearch:\n",
    "            mult = minimize_scalar(search_error,bounds=(0,0.1,3),tol=(threshold/4)**2,options={'maxiter':search_rounds,'disp':True})\n",
    "            if verbose:\n",
    "                print (\"linesearch result:\",mult)\n",
    "            chg_amt = mult.x\n",
    "        else:\n",
    "            #if not doing linesearch\n",
    "            #don't change perturbation\n",
    "            chg_amt = 1.0\n",
    "\n",
    "        final_delta = delta*chg_amt\n",
    "        if verbose:\n",
    "            print ('perturbation max magnitude:',final_delta.max())\n",
    "\n",
    "        final_delta = np.clip(delta,-weight_clip,weight_clip)\n",
    "        new_params = params + final_delta\n",
    "\n",
    "        if verbose:\n",
    "            print ('max post-perturbation weight magnitude:',abs(new_params).max())\n",
    "\n",
    "        if verbose:\n",
    "            print(\"divergence:\", search_error(chg_amt,raw=True))\n",
    "\n",
    "        diff = np.sqrt(((new_params - params)**2).sum())\n",
    "        if verbose:\n",
    "            print(\"mutation size: \", diff)\n",
    "\n",
    "        return new_params\n",
    "    \n",
    "    def run(self, envs, reset=True):\n",
    "        '''Evaluation for all the environments\n",
    "        Args:\n",
    "            envs: all the MAB environments\n",
    "            reset: flag for resetting the environment \n",
    "        '''\n",
    "        global state_archive\n",
    "        self.net_rwd = 0\n",
    "        self.matches = 0\n",
    "        self.score = 0\n",
    "        for env in envs:\n",
    "            for _ in range(self.trials):\n",
    "                arm = self.pull()\n",
    "                r = env.pull_arm(arm)\n",
    "                self.info[arm]['value'] += (r-self.info[arm]['value'])/self.info[arm]['no_visited']\n",
    "                self.net_rwd += r \n",
    "                self.score += int(arm==env.best_arm)\n",
    "                self.matches += 1\n",
    "            state_archive.appendleft(random.choice(self.buffer))\n",
    "            self.reset()\n",
    "            if reset:\n",
    "                env.reset()\n",
    "        self.fitness = self.net_rwd/self.matches        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation:  0\n",
      "pop fitness 0.49568000000000006\n",
      "elite fitness 0.54128\n",
      "Generation:  50\n",
      "pop fitness 0.6067\n",
      "elite fitness 0.6845600000000002\n",
      "Generation:  100\n",
      "pop fitness 0.6201\n",
      "elite fitness 0.69632\n",
      "Generation:  150\n",
      "pop fitness 0.6677400000000001\n",
      "elite fitness 0.7389999999999999\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from functools import reduce\n",
    "\n",
    "logging.info('run_master: {}'.format(args))\n",
    "\n",
    "\n",
    "\n",
    "# population size\n",
    "psize = int(args['pop_size'])\n",
    "#mutation magnitude\n",
    "mag = float(args['mutation_mag'])\n",
    "# number of generations\n",
    "generations = int(args['max_gen'])\n",
    "#number of arms\n",
    "no_arms = int(args['arms'])\n",
    "#Number of samples for each bandit problem\n",
    "trials = int(args['trials'])\n",
    "\n",
    "#degree of exploitation vs exploration\n",
    "greedy_kill = 5\n",
    "greedy_select = 5\n",
    "\n",
    "#setting the enviroment\n",
    "all_envs = []\n",
    "for i in range(psize):\n",
    "    envs  = [Enviroment(is_bernoulli=True, no_arms=no_arms) for _ in range(10)]\n",
    "    all_envs.append(envs)\n",
    "\n",
    "#set of elite agent\n",
    "elite = [None]*int(psize/2)\n",
    "\n",
    "\n",
    "# Average rewards for ES\n",
    "avg_elite_rwd = 0\n",
    "avg_rwd = 0\n",
    "rwds = []\n",
    "elite_rwds = []\n",
    "\n",
    "#initilizing population\n",
    "population = []\n",
    "for _ in range(psize):\n",
    "    population.append(Individual(no_arms=no_arms, mag=mag, trials=trials))  \n",
    "\n",
    "for gen in range(generations):\n",
    "\n",
    "    #Doing rollouts\n",
    "    [indv.run(all_envs[i]) for i, indv in enumerate(population)]\n",
    "\n",
    "    #Getting elite agent        \n",
    "    for i in range(len(elite)):\n",
    "        parents = random.sample(population, greedy_select)\n",
    "        parent = reduce(lambda x, y: x if x.fitness > y.fitness else y, parents)\n",
    "        elite[i] = copy.deepcopy(parent)\n",
    "\n",
    "    rwds.append(np.mean([ind.fitness for ind in population]))\n",
    "    elite_rwds.append(np.mean([ind.fitness for ind in elite]))\n",
    "    #logging\n",
    "    logging.info('Generation: {}'.format(gen))\n",
    "    logging.info('pop fitness: {}'.format(np.mean([ind.fitness for ind in population])))\n",
    "    logging.info('elite fitness: {}'.format(np.mean([ind.fitness for ind in elite])))\n",
    "    \n",
    "    if gen%50==0:\n",
    "        print('Generation: ', gen)\n",
    "        print('pop fitness', np.mean([ind.fitness for ind in population]))\n",
    "        print('elite fitness', np.mean([ind.fitness for ind in elite]))\n",
    "\n",
    "    #creation of new off springs, and their evaluation in MAB problems\n",
    "    for j, parent in enumerate(elite):\n",
    "        for i in range(int(psize/len(elite))):\n",
    "            child = parent.mutate()\n",
    "            child.run(all_envs[j+i])\n",
    "            population.append(child)\n",
    "\n",
    "\n",
    "    #Killing\n",
    "    for _ in range(int(psize/len(elite))*len(elite)):\n",
    "        to_kill = random.sample(population, greedy_kill)\n",
    "        to_kill = reduce(lambda x, y: x if x.fitness < y.fitness else y, to_kill)\n",
    "        population.remove(to_kill)\n",
    "\n",
    "\n",
    "\n",
    "#setting UCB agent\n",
    "ucb = AgentUCB(no_arms)\n",
    "\n",
    "#Average reward of UCB agent\n",
    "ucb_rwd = 0\n",
    "for env in envs:\n",
    "    for _ in range(trials):    \n",
    "        arm = ucb.pull()\n",
    "        r = env.pull_arm(arm)\n",
    "        ucb_rwd += r\n",
    "        ucb.update(arm, r)\n",
    "    ucb.reset()\n",
    "\n",
    "ucb_rwd /= len(envs)*trials\n",
    "\n",
    "\n",
    "#Plotting the training graph\n",
    "plt.plot(range(len(rwds)), rwds)\n",
    "plt.plot(range(len(rwds)), elite_rwds)\n",
    "plt.plot(range(len(rwds)), [ucb_rwd]*len(rwds))\n",
    "plt.ylabel('Returns')\n",
    "plt.xlabel('Generations') \n",
    "plt.legend(['pop_avg_return', 'elite_avg_return', 'UCB return'], loc='lower right')\n",
    "\n",
    "\n",
    "\n",
    "if args['save_result']:\n",
    "        if not args['noise']:\n",
    "            plt.savefig('results/'+args['layers'] + 'x' + args['hidden'] + 'mag' + args['mutation_mag'] + 'arms' + args['arms'] + 'psize' + args['pop_size'] + 'trials' + args['trials'] + args['name'] + '/training'+'.svg', format='svg')\n",
    "        else:\n",
    "            plt.savefig('results/'+args['layers'] + 'x' + args['hidden'] + 'mag' + args['mutation_mag'] + 'arms' + args['arms'] + 'psize' + args['pop_size'] + 'trials' + args['trials'] + args['name'] + '/noise_training'+'.svg', format='svg')\n",
    "\n",
    "plt.show()\n",
    "#plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_envs  = [Enviroment(is_bernoulli=True, no_arms=no_arms) for _ in range(10)]\n",
    "test_pop = []\n",
    "test_elite = []\n",
    "test_ucb = []\n",
    "\n",
    "test_cummBest_pop = []\n",
    "test_cummBest_elite = []\n",
    "test_cummBest_ucb = []\n",
    "for env in test_envs:\n",
    "    test_rwd = 0\n",
    "    test_cummBest_rwd = 0\n",
    "    for indv in population:\n",
    "            indv.played = False\n",
    "            indv.score = 0\n",
    "            indv.fitness = 0\n",
    "            indv.run([env], reset=False)\n",
    "            test_rwd += indv.fitness\n",
    "            test_cummBest_rwd += indv.score/indv.matches   \n",
    "    test_pop.append(round(test_rwd/psize, 3))\n",
    "    test_cummBest_pop.append(round(test_cummBest_rwd/psize, 3))\n",
    "\n",
    "    test_rwd = 0\n",
    "    test_cummBest_rwd = 0\n",
    "    for indv in elite:\n",
    "            indv.played = False\n",
    "            indv.score = 0\n",
    "            indv.fitness = 0\n",
    "            indv.run([env], reset=False)\n",
    "            test_rwd += indv.fitness\n",
    "            test_cummBest_rwd += indv.score/indv.matches   \n",
    "    test_elite.append(round(test_rwd/psize, 3))\n",
    "    test_cummBest_elite.append(round(test_cummBest_rwd/psize, 3))\n",
    "\n",
    "    test_rwd = 0\n",
    "    test_cummBest_rwd = 0\n",
    "    for _ in range(trials):    \n",
    "            arm = ucb.pull()\n",
    "            r = env.pull_arm(arm)\n",
    "            test_rwd += r\n",
    "            test_cummBest_rwd += int(env.best_arm==arm)\n",
    "            ucb.update(arm, r)\n",
    "    ucb.reset()\n",
    "    test_ucb.append(round(test_rwd/trials, 3))\n",
    "    test_cummBest_ucb.append(round(test_cummBest_rwd/trials, 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = ['Env ' + str(i) for i in range(len(test_envs))]\n",
    "labels.append('Avg')\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.5  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "test_pop.append(round(np.mean(test_pop), 3))\n",
    "test_elite.append(round(np.mean(test_elite), 3))\n",
    "test_ucb.append(round(np.mean(test_ucb), 3))\n",
    "\n",
    "rects1 = ax.bar(x - width/2, test_pop, width/2, label='Population')\n",
    "rects2 = ax.bar(x, test_elite, width/2, label='Elite')\n",
    "rects3 = ax.bar(x + width/2, test_ucb, width/2, label='UCB')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Scores for different envirnoments')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(height),\n",
    "                xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                xytext=(0, 3),  # 3 points vertical offset\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "if args['save_result']:\n",
    "        if not args['noise']:\n",
    "            plt.savefig('results/'+args['layers'] + 'x' + args['hidden'] + 'mag' + args['mutation_mag'] + 'arms' + args['arms'] + 'psize' + args['pop_size'] + 'trials' + args['trials'] + args['name'] + '/testing'+'.svg', format='svg')\n",
    "        else:\n",
    "            plt.savefig('results/'+args['layers'] + 'x' + args['hidden'] + 'mag' + args['mutation_mag'] + 'arms' + args['arms'] + 'psize' + args['pop_size'] + 'trials' + args['trials'] + args['name'] + '/noise_testing'+'.svg', format='svg')\n",
    "\n",
    "plt.show()\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:\n",
      "{'arms': '10', 'mutation_mag': '0.01', 'pop_size': '50', 'hidden': '32', 'layers': '1', 'name': 'UCBvsES', 'save_result': True, 'noise': False, 'trials': '100', 'message': '', 'max_gen': '200'}\n"
     ]
    }
   ],
   "source": [
    "#Best Arm\n",
    "\n",
    "labels = ['Env ' + str(i) for i in range(len(test_envs))]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.5  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "rects1 = ax.bar(x - width/2, test_cummBest_pop, width/2, label='Population')\n",
    "rects2 = ax.bar(x, test_cummBest_elite, width/2, label='Elite')\n",
    "rects3 = ax.bar(x + width/2, test_cummBest_ucb, width/2, label='UCB')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Scores for different envirnoments')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(height),\n",
    "                xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                xytext=(0, 3),  # 3 points vertical offset\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "if args['save_result']:\n",
    "        if not args['noise']:\n",
    "            plt.savefig('results/'+args['layers'] + 'x' + args['hidden'] + 'mag' + args['mutation_mag'] + 'arms' + args['arms'] + 'psize' + args['pop_size'] + 'trials' + args['trials'] + args['name'] + '/testingCummutativeBest'+'.svg', format='svg')\n",
    "        else:\n",
    "            plt.savefig('results/'+args['layers'] + 'x' + args['hidden'] + 'mag' + args['mutation_mag'] + 'arms' + args['arms'] + 'psize' + args['pop_size'] + 'trials' + args['trials'] + args['name'] + '/noise_testingCummutativeBest'+'.svg', format='svg')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "#plt.close()\n",
    "print('Done:' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
